{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a329b38-95e6-49ea-ad52-fc90201b689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/med/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/miniconda3/envs/med/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from openslide import OpenSlide\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from utils.focal_loss import FocalLoss\n",
    "\n",
    "SEED = 42\n",
    "dataset_base_path = \"./datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cececdd-f268-43d4-9c51-c32ab7ae57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./csv_dir/train_outcomes.csv') # biopsy_id, label\n",
    "test_df = pd.read_csv('./csv_dir/test_outcomes.csv')\n",
    "\n",
    "train_mapping = pd.read_csv('./csv_dir/train_mapping.csv') # slide_id, biopsy_id, img path\n",
    "test_mapping = pd.read_csv('./csv_dir/test_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee20f6e-0cac-4e52-bfb0-0853caadd0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outcome_map = {}\n",
    "\"\"\"\n",
    "key: biopsy_id\n",
    "value: stage_number 0,1,2,3,4 (exclude NaN)\n",
    "\"\"\"\n",
    "for idx, row in train_df.iterrows():\n",
    "    train_outcome_map[row['biopsy_id']] = row['label']\n",
    "\n",
    "train_slide_map = {}\n",
    "\"\"\"\n",
    "key: slide_id\n",
    "value: Tuple(biopsy_id, slide_path, label)\n",
    "\"\"\"\n",
    "for idx, row in train_mapping.iterrows():\n",
    "    train_slide_map[row['slide_id']] = (row['biopsy_id'], row['downsampled_path'], train_outcome_map[row['biopsy_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3177ad9-33c3-4254-b2a9-a4bdf07fadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outcome_map = {}\n",
    "\"\"\"\n",
    "key: biopsy_id\n",
    "value: stage_number 0,1,2,3,4 (exclude NaN)\n",
    "\"\"\"\n",
    "for idx, row in test_df.iterrows():\n",
    "    test_outcome_map[row['biopsy_id']] = row['label']\n",
    "\n",
    "test_slide_map = {}\n",
    "\"\"\"\n",
    "key: slide_id\n",
    "value: Tuple(biopsy_id, slide_path, label)\n",
    "\"\"\"\n",
    "for idx, row in test_mapping.iterrows():\n",
    "    # print(row['biopsy_id'])\n",
    "    test_slide_map[row['slide_id']] = (row['biopsy_id'], row['downsampled_path'], test_outcome_map[row['biopsy_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b662f319-9f33-46d6-86c3-6970c595d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6810"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_slide_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aadf01f-5b29-45e5-a088-195057fc81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aug_train = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.RandomResizedCrop(size=224,scale=(0.8,1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "transform_aug_test = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a15598-ed25-4ae3-abfe-d33e9ca839f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, slide_map, mode='train', transform=None): \n",
    "        self.slide_map = slide_map\n",
    "        self.data = list(slide_map.values())\n",
    "        \n",
    "        self.mode = mode # train/test\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        biopsy_id, path, label = self.data[index]\n",
    "        x_pil = Image.open(dataset_base_path + path)\n",
    "        # if self.mode=='train': x_tensor = transform_aug_train(x_pil)\n",
    "        # elif self.mode in ['test', 'holdout']: x_tensor = transform_aug_test(x_pil)\n",
    "        x_tensor = self.transform(x_pil)\n",
    "        return x_tensor, label, biopsy_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slide_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa793b9f-d9ab-4fe5-81f3-c1c4366173bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1.0e-4\n",
    "\n",
    "hidden_dim = 2048 # ResNet50: 2048, ResNet18: 512\n",
    "num_classes = 5\n",
    "out_dim = num_classes # [0,1,2,3,4]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13c5e2f-e74e-426a-9f76-3a98ce6e89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(train_slide_map, mode='train', transform=transform_aug_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = ImageDataset(test_slide_map, mode='test', transform=transform_aug_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8708964d-89b5-4954-944b-199486adde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ce_loss(y_pred, y_true):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    return loss_fn(y_pred, y_true)\n",
    "\n",
    "def get_focal_loss(y_pred, y_true):\n",
    "    loss_fn = FocalLoss()\n",
    "    return loss_fn(y_pred, y_true)\n",
    "\n",
    "criterion = get_focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "978d2d6f-7552-4a71-b4e2-72fb9b6a9c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(np.arange(num_classes))\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    # assume y_true: [0,1,2,3,4,3,2,...] discrete numbers\n",
    "    # assume y_pred: tensor of shape (batch_size, num_classes)\n",
    "    # where num_classes = 5 for this task\n",
    "\n",
    "    # compute AUC for each class\n",
    "    \"\"\"\n",
    "    y_true_onehot = label_binarizer.transform(y_true)\n",
    "    macro_roc_auc_ovr = roc_auc_score(\n",
    "        y_true_onehot,\n",
    "        y_pred,\n",
    "        multi_class=\"ovr\",\n",
    "        average=\"macro\",\n",
    "    )\n",
    "    return macro_roc_auc_ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54eb4d01-9a57-4ca3-a8fb-e46462273f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "# model.load_state_dict(torch.load('./checkpoints/resnet50-11ad3fa6.pth'), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7533f3-891c-4929-ad58-52a5a8dba5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    # nn.Linear(hidden_dim, hidden_dim//16),\n",
    "    # nn.GELU(),\n",
    "    # nn.Linear(hidden_dim//16, out_dim),\n",
    "    nn.Linear(hidden_dim, out_dim),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0369fe48-acc4-4f95-9414-edf7c8d79a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for step, data in enumerate(dataloader):\n",
    "        # print(f\"Training... Step={step}\")\n",
    "        batch_x, batch_y, batch_biopsy_id = data\n",
    "        batch_x, batch_y = (\n",
    "            batch_x.float().to(device),\n",
    "            batch_y.type(torch.LongTensor).to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = loss_fn(output, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    metric_train_loss = np.array(train_loss).mean()\n",
    "    return metric_train_loss\n",
    "\n",
    "def val_epoch(model, dataloader):\n",
    "    y_pred = {} # key: biopsy_id, value: List[slice_stage_pred]\n",
    "    y_true = {} # key: biopsy_id, value: List[slice_stage_pred]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(dataloader):\n",
    "            # if step % 50 == 0: print(f\"Validating... Step={step}\")\n",
    "            batch_x, batch_y, batch_biopsy_id = data\n",
    "            batch_x, batch_y = (\n",
    "                batch_x.float().to(device),\n",
    "                batch_y.type(torch.LongTensor).to(device),\n",
    "            )\n",
    "            output = model(batch_x)\n",
    "            # output = torch.argmax(output, dim=-1)\n",
    "            output = output.detach().cpu().numpy().tolist()\n",
    "            batch_y = batch_y.detach().cpu().numpy().tolist()\n",
    "\n",
    "            for i in range(len(batch_biopsy_id)):\n",
    "                biopsy_id = batch_biopsy_id[i]\n",
    "                if biopsy_id not in y_pred:\n",
    "                    y_pred[biopsy_id] = []\n",
    "                    y_true[biopsy_id] = []\n",
    "                y_pred[biopsy_id].append(output[i])\n",
    "                y_true[biopsy_id].append(batch_y[i])\n",
    "    \n",
    "    prediction_list = []\n",
    "    ground_truth_list = []\n",
    "    for biopsy_id in y_pred:\n",
    "        preds = np.array(y_pred[biopsy_id])\n",
    "        truths = np.array(y_true[biopsy_id])\n",
    "        prediction_list.append(preds.mean(axis=0))\n",
    "        ground_truth_list.append(truths.mean())\n",
    "    prediction_list = np.array(prediction_list)\n",
    "    ground_truth_list = np.array(ground_truth_list)\n",
    "    # prediction_list = reverse_min_max_norm(prediction_list)\n",
    "    # nearest_discretize(prediction_list)\n",
    "    # ground_truth_list = reverse_min_max_norm(ground_truth_list)\n",
    "\n",
    "    score = get_score(ground_truth_list, prediction_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "638673fd-e751-4721-a060-fcc82950ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 1.6019854346911113\n",
      "Val Score: 0.4872571456783864\n",
      "Saving best model at Epoch 0\n",
      "Epoch 1: Loss = 1.5610058351799294\n",
      "Val Score: 0.5270871011405849\n",
      "Saving best model at Epoch 1\n",
      "Epoch 2: Loss = 1.5223368759508487\n",
      "Val Score: 0.5145326067085432\n",
      "Epoch 3: Loss = 1.5108514119077612\n",
      "Val Score: 0.5240893526090936\n",
      "Epoch 4: Loss = 1.5069434355806421\n",
      "Val Score: 0.5224757011117039\n",
      "Epoch 5: Loss = 1.5046704521885625\n",
      "Val Score: 0.5292574412299349\n",
      "Saving best model at Epoch 5\n",
      "Epoch 6: Loss = 1.5026188956366644\n",
      "Val Score: 0.5320000966088974\n",
      "Saving best model at Epoch 6\n",
      "Epoch 7: Loss = 1.4996669513207894\n",
      "Val Score: 0.5367302055871553\n",
      "Saving best model at Epoch 7\n",
      "Epoch 8: Loss = 1.4990704258282979\n",
      "Val Score: 0.5365601567496824\n",
      "Epoch 9: Loss = 1.496088197937718\n",
      "Val Score: 0.5415570001225559\n",
      "Saving best model at Epoch 9\n",
      "Epoch 10: Loss = 1.49545994732115\n",
      "Val Score: 0.5436670550544973\n",
      "Saving best model at Epoch 10\n",
      "Epoch 11: Loss = 1.4946082830429077\n",
      "Val Score: 0.540852721816125\n",
      "Epoch 12: Loss = 1.492108824076476\n",
      "Val Score: 0.5433552520848866\n",
      "Epoch 13: Loss = 1.4911535801710907\n",
      "Val Score: 0.5469687040578817\n",
      "Saving best model at Epoch 13\n",
      "Epoch 14: Loss = 1.4889400093643754\n",
      "Val Score: 0.5451081080334148\n",
      "Epoch 15: Loss = 1.4878673023647733\n",
      "Val Score: 0.5487970105631242\n",
      "Saving best model at Epoch 15\n",
      "Epoch 16: Loss = 1.4867557419670954\n",
      "Val Score: 0.5498026935031539\n",
      "Saving best model at Epoch 16\n",
      "Epoch 17: Loss = 1.4846744316595573\n",
      "Val Score: 0.552392372072678\n",
      "Saving best model at Epoch 17\n",
      "Epoch 18: Loss = 1.4838282642541107\n",
      "Val Score: 0.5549075610430969\n",
      "Saving best model at Epoch 18\n",
      "Epoch 19: Loss = 1.4822705939964012\n",
      "Val Score: 0.5547139773062149\n",
      "Epoch 20: Loss = 1.4798803748907867\n",
      "Val Score: 0.5569111680012895\n",
      "Saving best model at Epoch 20\n",
      "Epoch 21: Loss = 1.4793474078178406\n",
      "Val Score: 0.5601384191095782\n",
      "Saving best model at Epoch 21\n",
      "Epoch 22: Loss = 1.4776292421199657\n",
      "Val Score: 0.5605317145459787\n",
      "Saving best model at Epoch 22\n",
      "Epoch 23: Loss = 1.4771046042442322\n",
      "Val Score: 0.5614009472012531\n",
      "Saving best model at Epoch 23\n",
      "Epoch 24: Loss = 1.4729103247324626\n",
      "Val Score: 0.5637879601737215\n",
      "Saving best model at Epoch 24\n",
      "Epoch 25: Loss = 1.4733258971461543\n",
      "Val Score: 0.5623579716065186\n",
      "Epoch 26: Loss = 1.470744099881914\n",
      "Val Score: 0.5650800884672532\n",
      "Saving best model at Epoch 26\n",
      "Epoch 27: Loss = 1.4695690097632232\n",
      "Val Score: 0.5644155523665834\n",
      "Epoch 28: Loss = 1.4685934428815488\n",
      "Val Score: 0.5647024134040933\n",
      "Epoch 29: Loss = 1.4660939088574163\n",
      "Val Score: 0.5663986038502269\n",
      "Saving best model at Epoch 29\n",
      "Epoch 30: Loss = 1.4640864729881287\n",
      "Val Score: 0.5687628390786393\n",
      "Saving best model at Epoch 30\n",
      "Epoch 31: Loss = 1.4639484484990437\n",
      "Val Score: 0.5691384664374908\n",
      "Saving best model at Epoch 31\n",
      "Epoch 32: Loss = 1.4603599464451824\n",
      "Val Score: 0.569604387488657\n",
      "Saving best model at Epoch 32\n",
      "Epoch 33: Loss = 1.4590666183718928\n",
      "Val Score: 0.5706304338419848\n",
      "Saving best model at Epoch 33\n",
      "Epoch 34: Loss = 1.4584597371242665\n",
      "Val Score: 0.5705380440702232\n",
      "Epoch 35: Loss = 1.4569774093451324\n",
      "Val Score: 0.574548493719144\n",
      "Saving best model at Epoch 35\n",
      "Epoch 36: Loss = 1.455110783930178\n",
      "Val Score: 0.5761916577123372\n",
      "Saving best model at Epoch 36\n",
      "Epoch 37: Loss = 1.4533401992585924\n",
      "Val Score: 0.574436223550272\n",
      "Epoch 38: Loss = 1.4515712040442008\n",
      "Val Score: 0.5752354138935251\n",
      "Epoch 39: Loss = 1.4489359988106623\n",
      "Val Score: 0.5753339379710082\n"
     ]
    }
   ],
   "source": [
    "best_score = -1e8\n",
    "valid_step = 1\n",
    "\n",
    "early_stop_cnt = 0\n",
    "for epoch in range(epochs):\n",
    "    # print(f'Running epoch {epoch} ...')\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    print(f\"Epoch {epoch}: Loss = {train_loss}\")\n",
    "    if epoch % valid_step == 0:\n",
    "        metric_valid = val_epoch(model, test_loader)\n",
    "        print(\"Val Score:\", metric_valid)\n",
    "        if metric_valid > best_score:\n",
    "            early_stop_cnt = 0\n",
    "            best_score = metric_valid\n",
    "            print(f\"Saving best model at Epoch {epoch}\")\n",
    "            torch.save(model.state_dict(), f\"./checkpoints/model_resnet50_0416.ckpt\")\n",
    "        else:\n",
    "            early_stop_cnt += valid_step\n",
    "    if early_stop_cnt == 20:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
