{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/med/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/miniconda3/envs/med/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# from openslide import OpenSlide\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from utils.focal_loss import FocalLoss\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_mapping = pd.read_csv('./csv_dir/holdout_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_slide_map = {}\n",
    "\"\"\"\n",
    "key: slide_id\n",
    "value: Tuple(biopsy_id, slide_path, label=-1)\n",
    "\"\"\"\n",
    "for idx, row in holdout_mapping.iterrows():\n",
    "    holdout_slide_map[row['slide_id']] = (row['biopsy_id'], row['downsampled_path'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, slide_map): \n",
    "        self.slide_map = slide_map\n",
    "        self.data = list(slide_map.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        biopsy_id, path, label = self.data[index]\n",
    "        slide_id = path.split('/')[-1]\n",
    "        if 'train' in path:\n",
    "            x = torch.load('./datasets/train/'+slide_id)\n",
    "        else:\n",
    "            x = torch.load('./datasets/holdout/'+slide_id)\n",
    "        # x.shape = [3, 1024]  mean/max/min\n",
    "        return x, label, biopsy_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slide_map)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xx, label, biopsy_id = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    label = torch.tensor(label)\n",
    "    return xx_pad, x_lens, label, biopsy_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "momentum = 0.9\n",
    "weight_decay = 1.0e-8 # 1e-8\n",
    "\n",
    "hidden_dim = 1024\n",
    "num_classes = 5\n",
    "out_dim = num_classes # [0,1,2,3,4]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_dataset = FeatureDataset(holdout_slide_map)\n",
    "holdout_loader = torch.utils.data.DataLoader(holdout_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(np.arange(num_classes))\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    # assume y_true: [0,1,2,3,4,3,2,...] discrete numbers\n",
    "    # assume y_pred: tensor of shape (batch_size, num_classes)\n",
    "    # where num_classes = 5 for this task\n",
    "\n",
    "    # compute AUC for each class\n",
    "    \"\"\"\n",
    "    y_true_onehot = label_binarizer.transform(y_true)\n",
    "    macro_roc_auc_ovr = roc_auc_score(\n",
    "        y_true_onehot,\n",
    "        y_pred,\n",
    "        multi_class=\"ovr\",\n",
    "        average=\"macro\",\n",
    "    )\n",
    "    return macro_roc_auc_ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    hidden_dim = 1024\n",
    "    out_dim = num_classes = 5\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_dim = 1024\n",
    "        self.num_classes = 5\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.hidden_dim, self.hidden_dim//16)\n",
    "        self.activation = nn.GELU()\n",
    "        self.linear2 = nn.Linear(self.hidden_dim//16, self.num_classes)\n",
    "        self.proj = nn.Linear(self.hidden_dim, self.num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    # def forward(self, x, x_len):\n",
    "    def forward(self, x):\n",
    "        bs=x.shape[0]\n",
    "        \n",
    "        # x = self.linear1(x[:,0]) # only use mean feature\n",
    "        # x = self.activation(x)\n",
    "        # x = self.linear2(x) #\n",
    "        x = self.proj(x[:,0])\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "        # out = torch.zeros((bs, self.num_classes))\n",
    "        # for i in range(bs):\n",
    "        #     cur_len = x_len[i]\n",
    "        #     cur_out = torch.max(x[i][:cur_len], dim=0).values\n",
    "        #     out[i] = cur_out\n",
    "        # out = self.softmax(out)\n",
    "        # return out\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/model_0417.ckpt'), strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, dataloader):\n",
    "    y_pred = {} # key: biopsy_id, value: List[slice_stage_pred]\n",
    "    y_true = {} # key: biopsy_id, value: List[slice_stage_pred]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(dataloader):\n",
    "            # if step % 50 == 0: print(f\"Validating... Step={step}\")\n",
    "            batch_x, _, batch_biopsy_id = data\n",
    "            batch_x = batch_x.float().to(device)\n",
    "            output = model(batch_x)\n",
    "            # output = torch.argmax(output, dim=-1)\n",
    "            output = output.detach().cpu().numpy().tolist()\n",
    "\n",
    "            for i in range(len(batch_biopsy_id)):\n",
    "                biopsy_id = batch_biopsy_id[i]\n",
    "                if biopsy_id not in y_pred:\n",
    "                    y_pred[biopsy_id] = []\n",
    "                    y_true[biopsy_id] = []\n",
    "                y_pred[biopsy_id].append(output[i])\n",
    "    \n",
    "    submit_result_dict = {}\n",
    "    for biopsy_id in y_pred:\n",
    "        preds = np.array(y_pred[biopsy_id]).mean(axis=0)\n",
    "        stage = np.argmax(preds)\n",
    "        submit_result_dict[biopsy_id] = (preds, stage) \n",
    "    return submit_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_result_dict = val_epoch(model, holdout_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "biopsy_id_list = []\n",
    "probability_stage_list = []\n",
    "stage_list = []\n",
    "\n",
    "for biopsy_id in submit_result_dict:\n",
    "    biopsy_id_list.append(biopsy_id)\n",
    "    probability_stage_list.append(submit_result_dict[biopsy_id][0])\n",
    "    stage_list.append(submit_result_dict[biopsy_id][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "probability_stage_ndarray = np.array(probability_stage_list)\n",
    "\n",
    "with open(\"submit_0417.csv\", \"w\") as infile:\n",
    "    writer = csv.writer(infile)\n",
    "    # writer.writerow([\"header01\", \"header02\"])\n",
    "    for i in zip(biopsy_id_list, probability_stage_ndarray[:,0].tolist(), probability_stage_ndarray[:,1].tolist(), probability_stage_ndarray[:,2].tolist(), probability_stage_ndarray[:,3].tolist(), probability_stage_ndarray[:,4].tolist(), stage_list):\n",
    "        writer.writerow(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
